### A Tufts University DISC Workshop

## Description

Machine learning techniques are increasingly applicable in a wide range of fields. While it is possible to learn and apply many machine learning methods as "black boxes", practitioners of machine learning can be most effective when equipped with solid understanding of the relevant probabilistic underpinnings of the machine learning methodology they use. A conceptual grounding in probability can help one better explain, appropriately apply, customize, troubleshoot, and interpret analyses that involve machine learning techniques. This course aims at building up a foundational understanding of important concepts in probability as they relate to machine learning. The workshop will discuss random variables, probability densities, expectation, variance, covariance, bias, Bayes' theorem, regularization, entropy, and using these ideas to understand and interpret several practical approaches to regression, classification, and clustering.

This course will aimed primarily at two main audiences: those who are just beginning a foray into machine learning and who wish to begin with a solid probabilistic foundation, and those who have experience applying machine learning methodology as somewhat of a "black box" and who wish to bring a principled probabilist perspective to bear on these techniques.


Prerequisites: Calculus (even if it's a somewhat distant memory). Some knowledge of Python would also beneficial.


## Materials
### Day 1
[Slides](probability_for_machine_learning_slides_day1.pdf)

[Demo Notebook](https://colab.research.google.com/drive/1QW3G_hYhV6oiEso8UIWtl3-CtWPPmtLl?usp=sharing)

[Exercises](https://colab.research.google.com/drive/19p6Oyd11sl-rIzeki9eKMbypB2Zxnj5L?usp=sharing)	

[Exercise solutions](https://colab.research.google.com/drive/1yRWyYEUSufUxyRavJ2zUJvaxxCPUHcRr?usp=sharing)

For a little more about the beta-binomial setup of the coin-flipping example, the first sections of this [blog post](https://karinknudson.com/dirichletprocesses.html) discuss the specifics of the beta prior and posterior in more detail.

### Day 2
[Slides](probability_for_machine_learning_slides_day2.pdf)

[Exercises](https://colab.research.google.com/drive/18OawSMRYwPlUFrJKduX1kjtoJWwSKXAB?usp=sharing)	

[Regression notebook](https://colab.research.google.com/drive/1QXWgX7VjX5-fJvNSwqeHN-PetEl8eTdF?usp=sharing)

Reference: [Pattern Recognition and Machine Learning, Christopher Bishop](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)

### Day 3
[Slides](probability_for_machine_learning_slides_day3.pdf)
[Exercises](https://colab.research.google.com/drive/1HFjdvjSDZ1EFcF6aY4AkfpVPbqRne-oP?usp=sharing)
[Regression notebook 2](https://colab.research.google.com/drive/1VQyRKw2SNv2_ii3ciaOx7aiyWZOcvmLH?usp=sharing)
